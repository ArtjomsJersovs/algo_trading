target_col_name_txt='response', score_col_name='score', exp_pd_col_name='exp_pd')
model = train_model_get_scored_apps_and_model_metrics(
train_set_df=train_set,
hold_out_set_df=test_set,
features=names(select(train_set, -timestamp, -response, -modelling_subset, -random_number, -close_pct)),
nround_par=5, #710,
params=params,
target_col_name_txt='response', score_col_name='score', exp_pd_col_name='exp_pd')
model = train_model_get_scored_apps_and_model_metrics(
train_set_df=train_set,
hold_out_set_df=test_set,
features=names(select(train_set, -timestamp, -response, -modelling_subset, -random_number, -close_pct)),
nround_par=2, #710,
params=params,
target_col_name_txt='response', score_col_name='score', exp_pd_col_name='exp_pd')
model = train_model_get_scored_apps_and_model_metrics(
train_set_df=train_set,
hold_out_set_df=test_set,
features=names(select(train_set, -timestamp, -response, -modelling_subset, -random_number, -close_pct)),
nround_par=1, #710,
params=params,
target_col_name_txt='response', score_col_name='score', exp_pd_col_name='exp_pd')
model$scored_df %>% View()
model = train_model_get_scored_apps_and_model_metrics(
train_set_df=train_set,
hold_out_set_df=test_set,
features=names(select(train_set, -timestamp, -response, -modelling_subset, -random_number, -close_pct)),
nround_par=1, #710,
params=params,
target_col_name_txt='response', score_col_name='score', exp_pd_col_name='exp_pd')
model = train_model_get_scored_apps_and_model_metrics(
train_set_df=train_set,
hold_out_set_df=test_set,
features=names(select(train_set, -timestamp, -response, -modelling_subset, -random_number, -close_pct)),
nround_par=1, #710,
params=params,
target_col_name_txt='response', score_col_name='score', exp_pd_col_name='exp_pd')
model = train_model_get_scored_apps_and_model_metrics(
train_set_df=train_set,
hold_out_set_df=test_set,
features=names(select(train_set, -timestamp, -response, -modelling_subset, -random_number, -close_pct)),
nround_par=1, #710,
params=params,
target_col_name_txt='response', score_col_name='score', exp_pd_col_name='exp_pd')
model = train_model_get_scored_apps_and_model_metrics(
train_set_df=train_set,
hold_out_set_df=test_set,
features=names(select(train_set, -timestamp, -response, -modelling_subset, -random_number, -close_pct)),
nround_par=1000, #710,
params=params,
target_col_name_txt='response', score_col_name='score', exp_pd_col_name='exp_pd')
model = train_model_get_scored_apps_and_model_metrics(
train_set_df=train_set,
hold_out_set_df=test_set,
features=names(select(train_set, -timestamp, -response, -modelling_subset, -random_number, -close_pct)),
nround_par=500, #710,
params=params,
target_col_name_txt='response', score_col_name='score', exp_pd_col_name='exp_pd')
model = train_model_get_scored_apps_and_model_metrics(
train_set_df=train_set,
hold_out_set_df=test_set,
features=names(select(train_set, -timestamp, -response, -modelling_subset, -random_number, -close_pct)),
nround_par=100, #710,
params=params,
target_col_name_txt='response', score_col_name='score', exp_pd_col_name='exp_pd')
model$scored_df %>% View()
model$scored_df$exp_bin_result = case_when(model$scored_df$exp_pd>0.5~1,T~0)
model$scored_df %>% View()
table(model$scored_df$response,model$scored_df$exp_bin_result)
model$scored_df$exp_bin_result = case_when(model$scored_df$exp_pd>0.53~1,T~0)
table(model$scored_df$response,model$scored_df$exp_bin_result)
table(1,model$scored_df$exp_bin_result)
table(c(1,2),model$scored_df$exp_bin_result)
table(model$scored_df$random_number,model$scored_df$exp_bin_result)
response
table(model$scored_df$response,model$scored_df$exp_bin_result)
49/(49+71)
model$scored_df$exp_bin_result = case_when(model$scored_df$exp_pd>0.54~1,T~0)
table(model$scored_df$response,model$scored_df$exp_bin_result)
model$scored_df$exp_bin_result = case_when(model$scored_df$exp_pd>0.50~1,T~0)
table(model$scored_df$response,model$scored_df$exp_bin_result)
49/(49+71)
89/(89+31)
39/(23+39)
names(perf) = c('actual','predicted')
perf = table(model$scored_df$response,model$scored_df$exp_bin_result)
names(perf) = c('actual','predicted')
perf
names(perf)
names(perf)[1:2]
names(perf) =names(perf)[1:2]
perf
model$scored_df$exp_bin_result = case_when(model$scored_df$exp_pd>0.55~1,T~0)
perf = table(model$scored_df$response,model$scored_df$exp_bin_result)
table(model$scored_df$response,model$scored_df$exp_bin_result)
model$scored_df$exp_bin_result = case_when(model$scored_df$exp_pd>0.52~1,T~0)
table(model$scored_df$response,model$scored_df$exp_bin_result)
X = table(model$scored_df$response,model$scored_df$exp_bin_result)
x[2]
X[2]
X[1]
X[1,2]
acc = X[1,2]+X[2,2]
acc
acc = X[2,2]/(X[1,2]+X[2,2])
acc
model$scored_df$exp_bin_result = case_when(model$scored_df$exp_pd>0.53~1,T~0)
X = table(model$scored_df$response,model$scored_df$exp_bin_result)
acc = X[2,2]/(X[1,2]+X[2,2])
acc
model$scored_df$exp_bin_result = case_when(model$scored_df$exp_pd>0.535~1,T~0)
X = table(model$scored_df$response,model$scored_df$exp_bin_result)
acc = X[2,2]/(X[1,2]+X[2,2])
print(acc)
model$scored_df$exp_bin_result = case_when(model$scored_df$exp_pd>0.54~1,T~0)
X = table(model$scored_df$response,model$scored_df$exp_bin_result)
acc = X[2,2]/(X[1,2]+X[2,2])
print(acc)
model$scored_df$exp_bin_result = case_when(model$scored_df$exp_pd>0.545~1,T~0)
X = table(model$scored_df$response,model$scored_df$exp_bin_result)
acc = X[2,2]/(X[1,2]+X[2,2])
print(acc)
print(X)
model$model_var_importance
model$model_var_importance %>% excel_export
print(X)
print(acc)
acc_0 = X[2,1]/(X[1,1]+X[2,1])
print(acc_1)
print(acc_0)
acc_0 = X[1,1]/(X[1,1]+X[2,1])
print(acc_0)
print(acc_1)
model$scored_df$exp_bin_result = case_when(model$scored_df$exp_pd<0.465~-1,T~model$scored_df$exp_pd)
X = table(model$scored_df$response,model$scored_df$exp_bin_result)
X
model$scored_df$exp_bin_result
model$scored_df$exp_bin_result = case_when(model$scored_df$exp_pd>0.545~1,T~0)
model$scored_df$exp_bin_result = case_when(model$scored_df$exp_pd<0.465~-1,T~model$scored_df$exp_bin_result)
X = table(model$scored_df$response,model$scored_df$exp_bin_result)
X
library(here)
library(future.apply)
library(readxl)
library(excel.link)
library(hmeasure)
library(dplyr)
library(stringr)
library(magrittr)
library(tidyr)
source(here::here("Helper_functions.R"))
library(TTR)
library(xts)
# source(here::here('R','my-internal-projects','system', "load_settings.R"))
#source(here::here(system','R', "xgb wrapper functions summary.R"))
#library(devtools)
library(Sunny)
here()
data_d = read.csv('C:/Users/artjoms.jersovs/github/algo_trading/algo_trading/strategy_sandbox/datasets/BTCBUSD-1d-data.csv')
data_1h = read.csv('C:/Users/artjoms.jersovs/github/algo_trading/algo_trading/strategy_sandbox/datasets/BTCBUSD-1h-data.csv')
snp_data = read.csv('C:/Users/artjoms.jersovs/github/algo_trading/algo_trading/strategy_sandbox/014_R_code_xgboost_model/spy_daily_data.csv')
# feature generation ------------------------------------------------------
data_d = data_d %>% select(-close_time, -quote_av, -tb_base_av, -tb_quote_av, -ignore) %>%
mutate(timestamp = as.Date(timestamp),
close_pct = (close-lag(close))/lag(close) * 100,
open_pct = (open-lag(open))/lag(open) * 100,
high_pct = (high-lag(high))/lag(high) * 100,
low_pct = (low-lag(low))/lag(low) * 100,
weekday = lubridate::wday(as.Date(data_d$timestamp[1])))
#indicators
bb <-myBBands(data_d$close,n=20,sd=2)
bb = bb %>% as_tibble() %>% mutate(bb_h_l = up-dn,
bb_h_m = up-mavg,
bb_m_l = mavg-dn,
bb_h_l_pct = (bb_h_l-lag(bb_h_l))/lag(bb_h_l) * 100,
bb_h_m_pct = (bb_h_m-lag(bb_h_m))/lag(bb_h_m) * 100,
bb_m_l_pct = (bb_m_l-lag(bb_m_l))/lag(bb_m_l) * 100) %>%
select(bb_h_l_pct, bb_h_m_pct, bb_m_l_pct, pctB)
# rsi = as_tibble(myRSI(data_d$close, n = 15))
# names(rsi)= c('rsi_15')
ema_15 = as_tibble(myEMA(data_d$close,n = 15))
ema_40 = as_tibble(myEMA(data_d$close,n = 40))
ema = cbind(ema_15,ema_40)
names(ema) = c('ema_15','ema_40')
ema = ema %>% mutate(ema_diff = ema_15-ema_40,
ema_diff_pct = (ema_diff-lag(ema_diff))/lag(ema_diff) * 100)
#combine all together
data_d = cbind(data_d, bb, ema)
data_d = data_d %>% select(-open, -low, -high)
snp_data = snp_data %>% mutate(Date = as.Date(snp_data$Date,format = "%m/%d/%y")) %>% filter(Date>=as.Date('2019-09-19')) %>% arrange(Date)
names(snp_data) = paste0('snp_',names(snp_data))
snp_data = snp_data %>%
mutate(snp_close_pct = (snp_Close-lag(snp_Close))/lag(snp_Close) * 100,
snp_open_pct = (snp_Open-lag(snp_Open))/lag(snp_Open) * 100,
snp_high_pct = (snp_High-lag(snp_High))/lag(snp_High) * 100,
snp_low_pct = (snp_Low-lag(snp_Low))/lag(snp_Low) * 100,
) %>% select(-snp_Close, -snp_Open, -snp_High, -snp_Low)
data_d = data_d %>% left_join(snp_data, by=c('timestamp'='snp_Date'))
data_d_proc = data_d
lags = 5
for (lag in seq(1,lags)){
for (col in names(data_d_proc %>% select(close_pct, open_pct, high_pct, low_pct))){
col_name = paste0(col,'_lag_',lag)
data_d_proc[[col_name]] = lag(data_d_proc[[col]])
}
}
print('done')
data_d_proc = data_d_proc[-(1:40),]
# train test split --------------------------------------------------------
data_d_proc$random_number <- ceiling(5*runif(nrow(data_d_proc)))
data_d_proc_subsets = data_d_proc %>% mutate(modelling_subset=if_else(random_number==5,'Test','Train'))
#save_rds(app_ids_and_scores_model_subsets)
data_d_proc_subsets$target = case_when(lead(data_d_proc_subsets$close)>data_d_proc_subsets$close~1,T~0)
train_set = data_d_proc_subsets %>% filter(modelling_subset=='Train') %>% rename(response=target)
test_set = data_d_proc_subsets %>% filter(modelling_subset=='Test') %>% rename(response=target)
# fit ---------------------------------------------------------------------
params <- list(
#nrounds = 1000,
early_stopping_round = 100,
eta = 0.005,
subsample = 0.75,
colsample_bytree = 0.9,
max_depth = 5, #7,
min_child_weight = 5 #5
)
model = train_model_get_scored_apps_and_model_metrics(
train_set_df=train_set,
hold_out_set_df=test_set,
features=names(select(train_set, -timestamp, -response, -modelling_subset, -random_number, -close_pct)),
nround_par=100, #710,
params=params,
target_col_name_txt='response', score_col_name='score', exp_pd_col_name='exp_pd')
model = train_model_get_scored_apps_and_model_metrics(
train_set_df=train_set,
hold_out_set_df=test_set,
features=names(select(train_set, -timestamp, -response, -modelling_subset, -random_number, -close_pct)),
nround_par=100, #710,
params=params,
target_col_name_txt='response', score_col_name='score', exp_pd_col_name='exp_pd')
hist(model$scored_df$exp_pd)
model$scored_df$exp_bin_result = case_when(model$scored_df$exp_pd>0.50~1,T~0)
X = table(model$scored_df$response,model$scored_df$exp_bin_result)
acc_1 = X[2,2]/(X[1,2]+X[2,2])
acc_0 = X[1,1]/(X[1,1]+X[2,1])
print(X)
print(acc_1)
model$scored_df$exp_bin_result = case_when(model$scored_df$exp_pd>0.55~1,T~0)
X = table(model$scored_df$response,model$scored_df$exp_bin_result)
acc_1 = X[2,2]/(X[1,2]+X[2,2])
acc_0 = X[1,1]/(X[1,1]+X[2,1])
print(X)
print(acc_1)
model$scored_df$exp_bin_result = case_when(model$scored_df$exp_pd>0.51~1,T~0)
X = table(model$scored_df$response,model$scored_df$exp_bin_result)
acc_1 = X[2,2]/(X[1,2]+X[2,2])
acc_0 = X[1,1]/(X[1,1]+X[2,1])
print(X)
print(acc_1)
model$scored_df$exp_bin_result = case_when(model$scored_df$exp_pd>0.52
model$scored_df$exp_bin_result = case_when(model$scored_df$exp_pd>0.52~1,T~0)
model$scored_df$exp_bin_result = case_when(model$scored_df$exp_pd>0.52~1,T~0)
X = table(model$scored_df$response,model$scored_df$exp_bin_result)
acc_1 = X[2,2]/(X[1,2]+X[2,2])
acc_0 = X[1,1]/(X[1,1]+X[2,1])
print(X)
print(acc_1)
model$scored_df$exp_bin_result = case_when(model$scored_df$exp_pd>0.53~1,T~0)
model$scored_df$exp_bin_result = case_when(model$scored_df$exp_pd<0.465~-1,T~model$scored_df$exp_bin_result)
X = table(model$scored_df$response,model$scored_df$exp_bin_result)
acc_1 = X[2,2]/(X[1,2]+X[2,2])
acc_0 = X[1,1]/(X[1,1]+X[2,1])
print(X)
print(acc_1)
model$scored_df$exp_bin_result = case_when(model$scored_df$exp_pd>0.53~1,T~0)
#model$scored_df$exp_bin_result = case_when(model$scored_df$exp_pd<0.465~-1,T~model$scored_df$exp_bin_result)
X = table(model$scored_df$response,model$scored_df$exp_bin_result)
acc_1 = X[2,2]/(X[1,2]+X[2,2])
acc_0 = X[1,1]/(X[1,1]+X[2,1])
print(X)
print(acc_1)
model$scored_df$exp_bin_result = case_when(model$scored_df$exp_pd>0.54~1,T~0)
#model$scored_df$exp_bin_result = case_when(model$scored_df$exp_pd<0.465~-1,T~model$scored_df$exp_bin_result)
X = table(model$scored_df$response,model$scored_df$exp_bin_result)
acc_1 = X[2,2]/(X[1,2]+X[2,2])
acc_0 = X[1,1]/(X[1,1]+X[2,1])
print(X)
print(acc_1)
model$scored_df$exp_bin_result = case_when(model$scored_df$exp_pd>0.56~1,T~0)
#model$scored_df$exp_bin_result = case_when(model$scored_df$exp_pd<0.465~-1,T~model$scored_df$exp_bin_result)
X = table(model$scored_df$response,model$scored_df$exp_bin_result)
acc_1 = X[2,2]/(X[1,2]+X[2,2])
acc_0 = X[1,1]/(X[1,1]+X[2,1])
print(X)
print(acc_1)
model$scored_df$exp_bin_result = case_when(model$scored_df$exp_pd>0.50~1,T~0)
#model$scored_df$exp_bin_result = case_when(model$scored_df$exp_pd<0.465~-1,T~model$scored_df$exp_bin_result)
X = table(model$scored_df$response,model$scored_df$exp_bin_result)
acc_1 = X[2,2]/(X[1,2]+X[2,2])
acc_0 = X[1,1]/(X[1,1]+X[2,1])
print(X)
print(acc_1)
View(data_d_proc_subsets)
read_rds(data_d_proc)
here()
data_d = read.csv('C:/Users/artjoms.jersovs/github/algo_trading/algo_trading/strategy_sandbox/datasets/BTCBUSD-1d-data.csv')
data_1h = read.csv('C:/Users/artjoms.jersovs/github/algo_trading/algo_trading/strategy_sandbox/datasets/BTCBUSD-1h-data.csv')
snp_data = read.csv('C:/Users/artjoms.jersovs/github/algo_trading/algo_trading/strategy_sandbox/014_R_code_xgboost_model/spy_daily_data.csv')
# feature generation ------------------------------------------------------
data_d = data_d %>% select(-close_time, -quote_av, -tb_base_av, -tb_quote_av, -ignore) %>%
mutate(timestamp = as.Date(timestamp),
close_pct = (close-lag(close))/lag(close) * 100,
open_pct = (open-lag(open))/lag(open) * 100,
high_pct = (high-lag(high))/lag(high) * 100,
low_pct = (low-lag(low))/lag(low) * 100,
weekday = lubridate::wday(as.Date(data_d$timestamp[1])))
#indicators
bb <-myBBands(data_d$close,n=20,sd=2)
bb = bb %>% as_tibble() %>% mutate(bb_h_l = up-dn,
bb_h_m = up-mavg,
bb_m_l = mavg-dn,
bb_h_l_pct = (bb_h_l-lag(bb_h_l))/lag(bb_h_l) * 100,
bb_h_m_pct = (bb_h_m-lag(bb_h_m))/lag(bb_h_m) * 100,
bb_m_l_pct = (bb_m_l-lag(bb_m_l))/lag(bb_m_l) * 100) %>%
select(bb_h_l_pct, bb_h_m_pct, bb_m_l_pct, pctB)
# rsi = as_tibble(myRSI(data_d$close, n = 15))
# names(rsi)= c('rsi_15')
ema_15 = as_tibble(myEMA(data_d$close,n = 15))
ema_40 = as_tibble(myEMA(data_d$close,n = 40))
ema = cbind(ema_15,ema_40)
names(ema) = c('ema_15','ema_40')
ema = ema %>% mutate(ema_diff = ema_15-ema_40,
ema_diff_pct = (ema_diff-lag(ema_diff))/lag(ema_diff) * 100)
#combine all together
data_d = cbind(data_d, bb, ema)
data_d = data_d %>% select(-open, -low, -high)
snp_data = snp_data %>% mutate(Date = as.Date(snp_data$Date,format = "%m/%d/%y")) %>% filter(Date>=as.Date('2019-09-19')) %>% arrange(Date)
names(snp_data) = paste0('snp_',names(snp_data))
snp_data = snp_data %>%
mutate(snp_close_pct = (snp_Close-lag(snp_Close))/lag(snp_Close) * 100,
snp_open_pct = (snp_Open-lag(snp_Open))/lag(snp_Open) * 100,
snp_high_pct = (snp_High-lag(snp_High))/lag(snp_High) * 100,
snp_low_pct = (snp_Low-lag(snp_Low))/lag(snp_Low) * 100,
) %>% select(-snp_Close, -snp_Open, -snp_High, -snp_Low)
data_d = data_d %>% left_join(snp_data, by=c('timestamp'='snp_Date'))
data_d_proc = data_d
View(snp_data)
lags = 5
for (lag in seq(1,lags)){
for (col in names(data_d_proc %>% select(close_pct, open_pct, high_pct, low_pct))){
col_name = paste0(col,'_lag_',lag)
data_d_proc[[col_name]] = lag(data_d_proc[[col]],lag)
}
}
print('done')
data_d_proc = data_d_proc[-(1:40),]
# train test split --------------------------------------------------------
data_d_proc$random_number <- ceiling(5*runif(nrow(data_d_proc)))
data_d_proc_subsets = data_d_proc %>% mutate(modelling_subset=if_else(random_number==5,'Test','Train'))
#save_rds(app_ids_and_scores_model_subsets)
data_d_proc_subsets$target = case_when(lead(data_d_proc_subsets$close)>data_d_proc_subsets$close~1,T~0)
train_set = data_d_proc_subsets %>% filter(modelling_subset=='Train') %>% rename(response=target)
test_set = data_d_proc_subsets %>% filter(modelling_subset=='Test') %>% rename(response=target)
# fit ---------------------------------------------------------------------
params <- list(
#nrounds = 1000,
early_stopping_round = 100,
eta = 0.005,
subsample = 0.75,
colsample_bytree = 0.9,
max_depth = 5, #7,
min_child_weight = 5 #5
)
model = train_model_get_scored_apps_and_model_metrics(
train_set_df=train_set,
hold_out_set_df=test_set,
features=names(select(train_set, -timestamp, -response, -modelling_subset, -random_number, -close_pct)),
nround_par=100, #710,
params=params,
target_col_name_txt='response', score_col_name='score', exp_pd_col_name='exp_pd')
model = train_model_get_scored_apps_and_model_metrics(
train_set_df=train_set,
hold_out_set_df=test_set,
features=names(select(train_set, -timestamp, -response, -modelling_subset, -random_number, -close_pct)),
nround_par=100, #710,
params=params,
target_col_name_txt='response', score_col_name='score', exp_pd_col_name='exp_pd')
model = train_model_get_scored_apps_and_model_metrics(
train_set_df=train_set,
hold_out_set_df=test_set,
features=names(select(train_set, -timestamp, -response, -modelling_subset, -random_number, -close_pct)),
nround_par=1, #710,
params=params,
target_col_name_txt='response', score_col_name='score', exp_pd_col_name='exp_pd')
model = train_model_get_scored_apps_and_model_metrics(
train_set_df=train_set,
hold_out_set_df=test_set,
features=names(select(train_set, -timestamp, -response, -modelling_subset, -random_number, -close_pct)),
nround_par=10, #710,
params=params,
target_col_name_txt='response', score_col_name='score', exp_pd_col_name='exp_pd')
tune_params <- list(
nrounds = 1000,
early_stopping_rounds = 100,
eta = 0.001,
subsample = c(0.50,0.75, 0.9),
colsample_bytree = c(0.75, 0.9),
max_depth = c(2,3,4,5),
min_child_weight = c(4,6,8,12,15)
)
gridSize(tune_params)
all_model_inputs = names(select(train_set, -timestamp, -response, -modelling_subset, -random_number, -close_pct))
tune_params <- list(
nrounds = 1000,
early_stopping_rounds = 100,
eta = 0.001,
subsample = c(0.50,0.75, 0.9),
colsample_bytree = c(0.75, 0.9),
max_depth = c(2,3,4,5),
min_child_weight = c(4,6,8,12,15)
)
gridSize(tune_params)
model_grid_search_params = grid_search_gradient_boosting(
train.frame = train_set %>% select(response, one_of(all_model_inputs)),
param = tune_params,
set_seed = 1000,
#backup_file_name = 'grid_param_search',
n.runs = 200,
parallel_search = T,
logical_cores = T,
use_cores = 12, #8,
#grid_search_stopping_iter=20,
#features_permutation_number = 50, #200, #200, #300
#export_top_iterations_vars = 600,
#feature_subset_number_detection = T,
# feature_number_detection_vals = c(15)
)
export_grid_results_to_excel(model_grid_search_params)
params <- list(
#nrounds = 1000,
early_stopping_round = 100,
eta = 0.005,
subsample = 0.5,
colsample_bytree = 0.75,
max_depth = 2, #7,
min_child_weight = 4 #5
)
model = train_model_get_scored_apps_and_model_metrics(
train_set_df=train_set,
hold_out_set_df=test_set,
features=names(select(train_set, -timestamp, -response, -modelling_subset, -random_number, -close_pct)),
nround_par=10, #710,
params=params,
target_col_name_txt='response', score_col_name='score', exp_pd_col_name='exp_pd')
model = train_model_get_scored_apps_and_model_metrics(
train_set_df=train_set,
hold_out_set_df=test_set,
features=names(select(train_set, -timestamp, -response, -modelling_subset, -random_number, -close_pct)),
nround_par=5, #710,
params=params,
target_col_name_txt='response', score_col_name='score', exp_pd_col_name='exp_pd')
model = train_model_get_scored_apps_and_model_metrics(
train_set_df=train_set,
hold_out_set_df=test_set,
features=names(select(train_set, -timestamp, -response, -modelling_subset, -random_number, -close_pct)),
nround_par=6, #710,
params=params,
target_col_name_txt='response', score_col_name='score', exp_pd_col_name='exp_pd')
model = train_model_get_scored_apps_and_model_metrics(
train_set_df=train_set,
hold_out_set_df=test_set,
features=names(select(train_set, -timestamp, -response, -modelling_subset, -random_number, -close_pct)),
nround_par=6, #710,
params=params,
target_col_name_txt='response', score_col_name='score', exp_pd_col_name='exp_pd')
hist(model$scored_df$exp_pd)
model = train_model_get_scored_apps_and_model_metrics(
train_set_df=train_set,
hold_out_set_df=test_set,
features=names(select(train_set, -timestamp, -response, -modelling_subset, -random_number, -close_pct)),
nround_par=6, #710,
params=params,
target_col_name_txt='response', score_col_name='score', exp_pd_col_name='exp_pd')
hist(model$scored_df$exp_pd)
model$scored_df$exp_bin_result = case_when(model$scored_df$exp_pd>0.50~1,T~0)
#model$scored_df$exp_bin_result = case_when(model$scored_df$exp_pd<0.465~-1,T~model$scored_df$exp_bin_result)
X = table(model$scored_df$response,model$scored_df$exp_bin_result)
acc_1 = X[2,2]/(X[1,2]+X[2,2])
acc_0 = X[1,1]/(X[1,1]+X[2,1])
print(X)
print(acc_1)
model$scored_df$exp_bin_result = case_when(model$scored_df$exp_pd>0.502~1,T~0)
#model$scored_df$exp_bin_result = case_when(model$scored_df$exp_pd<0.465~-1,T~model$scored_df$exp_bin_result)
X = table(model$scored_df$response,model$scored_df$exp_bin_result)
acc_1 = X[2,2]/(X[1,2]+X[2,2])
acc_0 = X[1,1]/(X[1,1]+X[2,1])
print(X)
print(acc_1)
model$scored_df$exp_bin_result = case_when(model$scored_df$exp_pd>0.503~1,T~0)
#model$scored_df$exp_bin_result = case_when(model$scored_df$exp_pd<0.465~-1,T~model$scored_df$exp_bin_result)
X = table(model$scored_df$response,model$scored_df$exp_bin_result)
acc_1 = X[2,2]/(X[1,2]+X[2,2])
acc_0 = X[1,1]/(X[1,1]+X[2,1])
print(X)
print(acc_1)
model$scored_df$exp_bin_result = case_when(model$scored_df$exp_pd>0.50~1,T~0)
#model$scored_df$exp_bin_result = case_when(model$scored_df$exp_pd<0.465~-1,T~model$scored_df$exp_bin_result)
X = table(model$scored_df$response,model$scored_df$exp_bin_result)
acc_1 = X[2,2]/(X[1,2]+X[2,2])
acc_0 = X[1,1]/(X[1,1]+X[2,1])
print(X)
print(acc_1)
print(acc_0)
